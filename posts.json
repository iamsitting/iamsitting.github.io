[
  {
    "slug": "2025/05/romans1_3-4",
    "title": "The Seed of David Becoming the Son of God",
    "description": "My first blog post",
    "publishedAt": "2025-05-04",
    "author": {
      "name": "Carlos Salamanca"
    },
    "category": {
      "name": "Bible"
    },
    "content": "\n# The Seed of David Becoming the Son of God\n\nIn Romans 1:3–4, Paul introduces Jesus Christ with two profound titles:  \nHe is the **Seed of David according to the flesh**, and the **Son of God in power according to the Spirit of holiness out of the resurrection of the dead**.\n\nThis introduction reveals Christ's **two natures**:\n\n- As the **Seed of David**, He is a genuine man—born of a woman, descended from David, possessing the human nature God created in Adam. This nature was **untainted by sin**.\n- As the **Son of God**, He is divine—eternally begotten of the Father, possessing God's life and nature.\n\nYet what is striking is Paul’s choice of the word **“designated”** (or \"marked out\"):  \nHe writes that this Jesus, who came from David’s line, was **designated Son of God in power… out of the resurrection of the dead**.\n\nWait—wasn’t Jesus always the Son of God?\n\nYes. According to John 3:16, He is the **only begotten Son**, given to the world. He was God’s Son **before** the resurrection. But Paul is not speaking of His **eternal status**, but rather of something that happened **through resurrection**.\n\nTo understand this, we need to read **Acts 13:33**, where Paul applies **Psalm 2** to Jesus’ resurrection:\n\n> “You are My Son; today I have begotten You.”\n\nPaul interprets the **“today”** as the day of **resurrection**.  \nIn other words, Jesus’ resurrection was a kind of **begetting**—a public designation, even an *uplifting*, of His humanity.\n\nThough His humanity was sinless and perfect, it was not yet **glorified**. Through death and resurrection, God uplifted that humanity—uniting it fully with divinity in glory. This is why Paul says He was *designated Son of God in power*. What God had sought in Adam, He finally gained in Christ—God and man joined **not just in person**, but in **process and result**.\n\nThis is confirmed in **Hebrews 2:10** and **6:20**—Jesus is now the **Forerunner**, leading **many sons into glory**. This is not just leadership by authority, but by **pattern** and **participation**.\n\nIn **Romans 8:29**, Paul calls Him the **Firstborn among many brothers**.  \nHe is no longer the only begotten—He’s the **Firstborn**.  \nThat implies there are others.\n\nWho are they?\n\nAccording to **1 Peter 1:3**, *“God… has regenerated us… through the resurrection of Jesus Christ.”*\n\nHis resurrection was both His **designation** and our **regeneration**.\n\nNow, we too are on the same path. We are being **conformed to His image** (Rom. 8:29).  \nThis is the essence of the Christian life: not just to believe in Christ, but to **become like Christ**.\n\nSo when we pray, when we worship, when we serve—we are not just performing Christian activity.  \nWe are participating in a process:  \nWe are being conformed to the One who was designated Son of God in power.\n\n---\n\n## TL;DR\n\n- Jesus Christ is both **the Seed of David** (a genuine man) and **the Son of God** (divine).\n- Though always the Son, He was **designated Son of God in power** through **resurrection**—His perfect humanity was uplifted and glorified.\n- That resurrection was also **our regeneration** (1 Peter 1:3).\n- Now He is the **Firstborn among many brothers** (Rom. 8:29)—and we are being **conformed to His image**.\n- The Christian life is not just about doing things for God; it’s about being **transformed into the image of the resurrected, designated Son of God**.\n- This gives meaning to everything we do as believers.\n\n[Back to Home](/) "
  },
  {
    "slug": "2025/01/hangfire-tracing",
    "title": "Correlating Hangfire Background Jobs with HTTP Requests Using Datadog and .NET",
    "description": "Let's look at how to correlate hangfire jobs with http requests using datadog",
    "publishedAt": "2025-03-04",
    "author": {
      "name": "Carlos Salamanca"
    },
    "category": {
      "name": "Software Engineering"
    },
    "content": "\n# Correlating Hangfire Background Jobs with HTTP Requests Using Datadog and .NET\n\nDistributed tracing can feel like magic — until it doesn’t work.\n\nRecently, while integrating observability into a .NET web app using **Datadog**, I hit a wall. I had traces from HTTP requests. I had logs. I had background jobs running through **Hangfire**. But there was one crucial gap:\n\n> **Traces from my background jobs weren't correlated with the original HTTP requests.**\n\nHere's how I fixed it, and more importantly — **what I learned about tracing and observability along the way**.\n\n---\n\n## 🤯 The Problem: Disconnected Traces\n\nIn a typical setup:\n\n- An HTTP request comes in.\n- You queue a background job to do some work (via Hangfire).\n- That job executes *later*, often on a different thread or even a different machine.\n\nIf you're using **Datadog APM**, the default behavior is:\n\n- The HTTP request gets a trace.\n- The background job gets a *separate trace*.\n- You, the human, get lost trying to connect the dots.\n\nThat’s because **traces don’t magically carry over**. Unless you explicitly pass trace context, each job runs in its own isolated observability bubble.\n\n---\n\n## 🧠 A Quick Primer on Traces, Spans, and Context\n\nIf you're new to distributed tracing, here’s what you need to know:\n\n- A **trace** represents the full journey of a request through a system.\n- A **span** is a single unit of work (e.g., an HTTP handler, a DB call, or a background job).\n- Every span has:\n  - A `trace_id` (identifying the whole trace)\n  - A `span_id` (identifying the specific work)\n  - A `parent_span_id` (the span that called it)\n\nTo connect your background job to the original HTTP request, you need to:\n\n1. **Capture the trace and span info when queuing the job**\n2. **Rehydrate that context when the job executes**\n3. **Start a new span as a child of the original span**\n\n---\n\n## 🛠 The Solution in .NET with Hangfire and Datadog\n\n### Step 1: Capture the Trace Context\n\nWhen queuing a background job, we extract the current trace context using `Datadog.Trace` and save it to Hangfire's Job Parameters:\n\n```csharp\npublic string Enqueue(BackgroundJob job) : IBackgroundJobQueuer\n{\n    var jobId = _backgroundJobClient.Enqueue(p => p.Process(job));\n\n    var scope = Tracer.Instance.ActiveScope;\n    if (scope != null)\n    {\n        var traceId = scope.Span.TraceId.ToString();\n        var spanId = scope.Span.SpanId.ToString();\n\n        using var connection = JobStorage.Current.GetConnection();\n        connection.SetJobParameter(jobId, \"TraceId\", traceId);\n        connection.SetJobParameter(jobId, \"ParentSpanId\", spanId);\n    }\n\n    return jobId;\n}\n```\n\n---\n\n### Step 2: Create a Hangfire Filter to Restore the Context\n\nBefore the background job runs, we use a `IServerFilter` to start a new span linked to the original trace:\n\n```csharp\npublic sealed class DatadogTracingFilter : IServerFilter\n{\n    private const string ScopeKey = \"DatadogScope\";\n\n    public void OnPerforming(PerformingContext context)\n    {\n        var traceIdStr = context.Connection.GetJobParameter(context.BackgroundJob.Id, \"TraceId\");\n        var parentSpanIdStr = context.Connection.GetJobParameter(context.BackgroundJob.Id, \"ParentSpanId\");\n\n        if (ulong.TryParse(traceIdStr, out var traceId) &&\n            ulong.TryParse(parentSpanIdStr, out var parentSpanId))\n        {\n            var tracer = Tracer.Instance;\n\n            var settings = new SpanCreationSettings\n            {\n                Parent = new SpanContext(traceId, parentSpanId)\n            };\n\n            var scope = tracer.StartActive(\"background.job\", settings);\n            scope.Span.ResourceName = context.BackgroundJob.Job.Type.Name;\n            scope.Span.SetTag(\"hangfire.job_id\", context.BackgroundJob.Id);\n            scope.Span.SetTag(\"background.job_type\", context.BackgroundJob.Job.Type.FullName);\n            scope.Span.SetTag(\"dd.trace_id\", traceIdStr);\n\n            context.Items[ScopeKey] = scope;\n        }\n    }\n\n    public void OnPerformed(PerformedContext context)\n    {\n        if (context.Items.TryGetValue(ScopeKey, out var scopeObj) && scopeObj is Scope scope)\n        {\n            scope.Dispose();\n        }\n    }\n}\n```\n\n---\n\n### Step 3: Register the Filter\n\nMake sure this filter is registered globally in your Hangfire setup:\n\n```csharp\nGlobalJobFilters.Filters.Add(new DatadogTracingFilter());\n```\n\n---\n\n## 🧭 What I Learned (That Applies Beyond .NET)\n\n### 1. Observability is Not Automatic\n\nJust because you're using an APM tool doesn't mean your observability is complete. You still need to be intentional about **propagating context across boundaries** like queues, jobs, and microservices.\n\n### 2. Traces and Logs Are Not the Same\n\nYou might be logging a `trace_id`, but unless that ID is part of a real, active trace context — **your traces won’t be linked**.\n\n### 3. Spans Must Be Linked Explicitly\n\nCreating a new span doesn't mean it's part of an existing trace. To link spans, you must **pass the parent context** — either via headers (in web requests), or job metadata (like we did).\n\n### 4. Tags Help Humans, Context Helps Systems\n\nSetting `dd.trace_id` as a tag is helpful for searching, but it’s not enough to link spans. **Tags are for you; context is for the APM**.\n\n---\n\n## 📦 Bonus: Why Not OpenTelemetry?\n\nYes, OpenTelemetry could help standardize this, and Datadog supports OTLP ingestion. But:\n\n- OpenTelemetry is still evolving in .NET\n- Datadog’s native SDK offers powerful control\n- This solution works now — and plays well with Datadog’s UI\n\nThat said, the principles here still apply if you're using OTEL — it just changes **how** you carry and restore context.\n\n---\n\n## 🔚 Final Thoughts\n\nGetting this working took some deep dives — not just into code, but into how distributed tracing *really works*. But now, when I look at a trace in Datadog and see an HTTP request linked cleanly to a background job, it feels worth it.\n\n> Observability isn’t just about capturing data — it’s about **connecting it**.\n\n---\n\n👋 Have questions or want to see how this fits into your stack? Reach out or leave a comment!\n\n[Back to Home](/) "
  },
  {
    "slug": "2025/01/aspire",
    "title": "Making Microservices Manageable with .NET Aspire, Git Submodules, and OpenTelemetry",
    "description": "Let's look at .NET Aspire as a potential solution to microservices development",
    "publishedAt": "2025-02-05",
    "author": {
      "name": "Carlos Salamanca"
    },
    "category": {
      "name": "General"
    },
    "content": "\n# Making Microservices Manageable with .NET Aspire, Git Submodules, and OpenTelemetry\n\nMicroservices give us flexibility. They also give us a headache.\n\nAt their best, microservices enable independent deployment, scalability, and team autonomy. But too often, they introduce local development chaos, debugging nightmares, and operational overhead—especially when we're just trying to deliver cohesive **products**, not architecture for architecture's sake.\n\nThis post explores how we can tame microservices using [.NET Aspire](https://devblogs.microsoft.com/dotnet/introducing-dotnet-aspire/), Git submodules, and local OpenTelemetry tracing. We’ll walk through practical strategies to create a **monorepo-like developer experience**—even when you don’t have a monorepo.\n\n---\n\n## 👎 The Reality of Microservices in Practice\n\nWhile microservices are great for deployment and scalability, they tend to:\n\n- **Break local dev workflows**: You need to spin up multiple services manually, in the right order, with the right env variables and ports.\n- **Make debugging painful**: Tracing a request across multiple services becomes a guessing game.\n- **Fragment ownership**: Services owned by different teams may live in different repos, on different deployment pipelines, and with different assumptions.\n- **Slow onboarding**: New developers often spend more time setting up services than writing code.\n\nThese are real tradeoffs—and often overlooked when teams jump on the \"microservices\" bandwagon.\n\n---\n\n## ✅ But We’re Building Products\n\nDespite the architectural breakdown of services, what we’re actually delivering is a **product**. That means we care more about how all the pieces fit together than the internals of each individual service.\n\nWhen you're building a product:\n\n- **Local cohesion matters.**\n- **Cross-service observability matters.**\n- **Running everything quickly and predictably matters.**\n\nThis is where `.NET Aspire` comes in.\n\n---\n\n## 🚀 .NET Aspire to the Rescue\n\n`.NET Aspire` is a new stack from Microsoft designed to make building distributed apps easier. It gives you a structured way to define, compose, and run a multi-service application locally.\n\nAspire supports things like:\n\n- Declarative service definitions\n- Local dev orchestration (like Docker Compose, but smarter and .NET-native)\n- Native integration with OpenTelemetry\n- IDE tooling and launch profiles out of the box\n\nLet’s look at an example:\n\n```csharp\nvar builder = DistributedApplication.CreateBuilder(args);\n\nvar service1 = builder.AddProject(\"service1\", \"../services/service1/Service1.API.csproj\")\n    .WithHttpsEndpoint(port: 7001, name: \"api\");\n\nvar service2 = builder.AddProject(\"service2\", \"../services/service2/Service2.API.csproj\")\n    .WithReference(service1)\n    .WithEnvironment(\"Service1__Uri\", service1.GetEndpoint(\"api\"));\n\nvar frontend = builder.AddYarnApp(\"frontend\", \"../services/frontend\", \"dev\")\n    .WithReference(service1)\n    .WithReference(service2)\n    .WithEnvironment(\"VITE_SERVICE1_URL\", service1.GetEndpoint(\"api\"))\n    .WithEnvironment(\"PORT\", \"5174\")\n    .WithHttpsEndpoint(targetPort: 5174, port: 5173, name: \"client\");\n\nbuilder.Build().Run();\n```\n\nThis Aspire `Program.cs` script declares how your product is composed. It specifies startup order, environment variables, references, ports, and more—all in one place.\n\n---\n\n## 🔗 Git Submodules: Repo Independence, Dev Cohesion\n\nWhat if your services live in separate repositories?\n\nThat’s where Git submodules help. You can add each service as a submodule to your Aspire app repository:\n\n```bash\ngit submodule add https://example.com/service1 services/service1\ngit submodule add https://example.com/service2 services/service2\ngit submodule add https://example.com/frontend services/frontend\n```\n\nThis allows:\n\n- Teams to retain ownership and versioning of individual services\n- The Aspire app to pull them in for local dev and orchestration\n- Isolation of concerns with a single command to clone everything:\n\n```bash\ngit clone --recurse-submodules https://example.com/aspire-app\n```\n\n> ✅ Bonus: In your `.gitmodules`, specify `branch = main` if your submodules don’t default to it.\n\n---\n\n## 🔍 Distributed Tracing: Don’t Debug in the Dark\n\nLocal dev is one thing. But once multiple services are talking to each other, tracing becomes essential. Aspire supports OpenTelemetry (OTel) out of the box.\n\nYou can even add your own tracing collector:\n\n```csharp\nbuilder.AddOpenTelemetryCollector(\"otel\")\n    .WithHttpEndpoint(port: 4318);\n```\n\nAnd then configure your services and frontends to send traces to `http://localhost:4318`.\n\nFor a React/Vite frontend in dev mode:\n\n```env\n# .env file\nVITE_OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318\n```\n\nThen, in your code:\n\n```ts\nimport { WebTracerProvider } from '@opentelemetry/sdk-trace-web';\n\nif (import.meta.env.MODE === 'development') {\n  const provider = new WebTracerProvider();\n  // Configure exporter + tracing logic\n}\n```\n\nNow, whether it’s a `.NET API` or a `React app`, you can follow a trace from click to DB and back—all locally.\n\n---\n\n## 🧠 Big Takeaways\n\n1. **You don’t need a monorepo to get a monorepo-like experience.**\n   - Use `.NET Aspire` + Git submodules to orchestrate services locally.\n\n2. **Deliver products, not services.**\n   - Think about the full product experience, from frontend to DB, not just isolated deployables.\n\n3. **Use distributed tracing—even in dev.**\n   - Set up local OpenTelemetry to debug and diagnose with confidence.\n\n4. **Simplify local development.**\n   - Aspire helps you run your product with one command, instead of 5 terminals and a README.\n\n---\n\n## 🧪 Final Thoughts\n\nMicroservices are here to stay—but the way we develop with them has to evolve. `.NET Aspire`, Git submodules, and OpenTelemetry can bridge the gap between independent services and cohesive product delivery.\n\nIf you’re drowning in `docker-compose.yml` files or juggling 6 terminal windows every time you onboard a new dev, give Aspire a look. You might just enjoy building distributed systems again.\n\n\n[Back to Home](/) "
  },
  {
    "slug": "2025/01/key-habits",
    "title": "Key Habits of a Leader",
    "description": "Some reflections on The 7 Habits of Highly Effective People by Stephen Covey",
    "publishedAt": "2025-01-31",
    "author": {
      "name": "Carlos Salamanca"
    },
    "category": {
      "name": "Leadership"
    },
    "content": "\n# Some Key Habits of a Leader\n\nI recently finished reading The 7 Habits of Highly Effective People by Stephen Covey, and it was eye-opening! These habits aren’t just theories—they’re practical principles that have reshaped how I approach both work and life.\n\nA few habits that really hit home for me:\n\n## Win/Win\n\nThink Win/Win: As someone working with products, I’ve seen firsthand how prioritizing mutual success builds stronger relationships. When you aim for outcomes that benefit both customers and stakeholders, you create partnerships that last.\n\n## First Understand, Then Be Understood\n\nSeek First to Understand, Then to Be Understood: This one really changed how I handle conversations—especially tough ones. Listening with empathy has helped me uncover customer needs I might have missed and find clarity in complex team discussions.\n\n## Synergize\n\nSynergize: Collaboration isn’t just a buzzword—it’s a game changer. Some of the best solutions I’ve been part of didn’t come from me or any one person. They came from combining diverse perspectives across teams. It’s amazing what happens when you embrace creativity and trust in others’ expertise.\n\n## Sharpen the Saw\n\nSharpen the Saw: Covey talks about renewal, and this resonated deeply. I’ve realized how critical it is to invest in personal growth—whether it’s through learning, rest, or even stepping back to reflect. Growth isn’t a sprint; it’s a marathon.\n\n\n## Trust\nFor me, the biggest shift was embracing Covey’s concept of the “emotional bank account.” Every interaction—whether with customers, peers, or family—is a deposit or a withdrawal. Building trust, showing kindness, and keeping commitments aren’t just nice ideas; they’re the foundation of meaningful relationships.\n\nThese habits offer fresh remainders that tech is more than software—it’s about people. When we lead with empathy and collaboration, we don’t just deliver value; we create impact that lasts.\n\nWhat habits or principles have shaped how you work and lead?\n\n[Back to Home](/) "
  },
  {
    "slug": "2024/12/equifax",
    "title": "What I learned from Equifax",
    "description": "",
    "publishedAt": "2024-12-01",
    "author": {
      "name": "Carlos Salamanca"
    },
    "category": {
      "name": "Leadership"
    },
    "content": "\n# What I learned from Equifax\n\nThe Equifax data breach of 2017 was more than just a cybersecurity failure—it was an organizational one. Sensitive information from 147 million people was exposed, but what compounded the damage was how the company handled it. The breach started in May, but it took months for leadership, including the CEO, to even learn of the problem. By the time the public was informed, trust had been obliterated—not just because of the breach itself, but because of the delayed and opaque response.\n\nHere’s the hard truth: organizational failures of this magnitude rarely start with technical flaws. They stem from cultural gaps—gaps in transparency, accountability, and ownership.\n\nSo what lessons can we learn from Equifax?\n\n## 1. Transparency Must Start at the Top\n\nTransparency isn’t just about being upfront with customers. It’s about building a culture where bad news travels fast and effectively within the organization. Leaders must create an environment where teams feel empowered—and obligated—to escalate issues without fear of blame.\n\n## 2. Ownership is Organizational\n\nSecurity, like success, is everyone’s responsibility. A culture of ownership starts at the top and filters down. Leaders need to set the example, treating risks and vulnerabilities as shared challenges, not isolated team problems.\n\n## 3. Build Systems that Support Culture\n\nEven the best intentions mean little without processes to back them up. Organizations must invest in tools and workflows that enable rapid escalation, clear communication, and swift decision-making. Leadership cannot act on what they don’t know.\n\nThink about this: If a breach happened today, how long would it take for your organization’s leadership to learn about it? Would your teams have the trust and infrastructure to respond decisively? Would your customers hear the truth before rumors spread?\n\nThe Equifax breach reminds us that technical safeguards are only part of the equation. The bigger question is whether your organization has the cultural and structural readiness to face challenges head-on—with transparency and ownership leading the charge.\n\nWhen challenges arise, does your organization’s culture enable a quick, honest response? Or does it risk letting small issues snowball into crises?\n\n[Back to Home](/) "
  }
]